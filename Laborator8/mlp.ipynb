{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucur Robert - Adrian\n",
    "## Grupa 10LF381\n",
    "## Multi-Layer Perceptron - mlp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.688762Z",
     "start_time": "2020-04-15T05:32:33.683775Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.703722Z",
     "start_time": "2020-04-15T05:32:33.694747Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_file(path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the data from the file stored at :param path: and returns the \n",
    "    input values and the class labels.\n",
    "    :param path: path of a CVS file with data\n",
    "    :return: a tuple containing the input matrix of shape (n, p) and a line \n",
    "    vector with the m class labels in {0, ..., 9}\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, header = None)                   # citire date din fisierul dat de path\n",
    "    X = df.values[:, 1:].transpose()                       # scrieti cod\n",
    "    y = df.values[:, 0].reshape(-1,1).transpose()          # scrieti cod\n",
    "    assert X.ndim ==  2, 'Matrix required for input values'\n",
    "    assert y.ndim == 2, 'Column matrix required for labels'\n",
    "    assert y.shape == (1, X.shape[1]), 'Same number of lines is required'\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.710703Z",
     "start_time": "2020-04-15T05:32:33.706715Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train = './data/mnist_train.csv'\n",
    "path_test = './data/mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.182596Z",
     "start_time": "2020-04-15T05:32:33.713696Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_file(path_train)\n",
    "assert X_train.shape == (784, 60000)\n",
    "assert y_train.shape == (1, 60000)\n",
    "\n",
    "X_test, y_test = load_file(path_test)\n",
    "assert X_test.shape == (784, 10000)\n",
    "assert y_test.shape == (1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.194562Z",
     "start_time": "2020-04-15T05:32:38.184589Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_values(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Scales the values to range [0, 1].\n",
    "    :param X: an (m, n) matrix with values between 0 and 255.\n",
    "    :return: an (m, n) matrix containing values of :param X: scaled in [0, 1]\n",
    "    \"\"\"\n",
    "    result = np.divide(X, np.max(X))                 # scrieti cod\n",
    "    assert 0 <= np.min(result) <= np.max(result) <= 1, 'Scaled values should be in [0, 1]'\n",
    "    assert X.shape == result.shape, 'Scaling preserves shape'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.531663Z",
     "start_time": "2020-04-15T05:32:38.203540Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = scale_values(X_train)\n",
    "assert X_train.shape == (784, 60000)\n",
    "X_test = scale_values(X_test)\n",
    "assert X_test.shape == (784, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:41:07.997557Z",
     "start_time": "2019-11-24T15:41:07.991110Z"
    }
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.541636Z",
     "start_time": "2020-04-15T05:32:38.535651Z"
    }
   },
   "outputs": [],
   "source": [
    "m = 10                          # number of classes\n",
    "n, p = X_train.shape\n",
    "architecture = [n, 100, m]      # list: [input_size, hidden1, hidden2, ..., output_size]\n",
    "\n",
    "assert len(architecture) >= 3, 'At least one hidden layer'\n",
    "assert architecture[0] == n\n",
    "assert architecture[-1] == m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponderile sunt initializate conform strategiei lui Xavier Glorot. Pentru o matrice de ponderi $W^{[l]}$ de forma $n_{l} \\times n_{l-1}$, ponderile pot fi initializate cu o distributie uniforma in intervalul \n",
    "$$\n",
    "\\left[-\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}, +\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}\\right]\n",
    "$$\n",
    "\n",
    "Ponderile de bias se obisnuiesc a se initializa cu 0; intializarea aleatoare a ponderilor W este considerata suficienta pentru a obtine spargerea simetriei.\n",
    "\n",
    "Ref: [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.567564Z",
     "start_time": "2020-04-15T05:32:38.545624Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_weights(architecture: List[int], init_type:str='glorot_uniform') -> Tuple[List[np.array], List[np.array]]:\n",
    "    \"\"\"Creates the list of weights and biases for the given architecture.\n",
    "    :param architecture: list of number of nodes in each layer \n",
    "    (including input and ouotput layers)\n",
    "    :param init_type: name of initialization parameter. Defaults to \n",
    "    'glorot_uniform', add other supported initializtion strategies.\n",
    "    :return: a tuple containing: list of weight matrices W, a list of bias \n",
    "    column vectors. The two lists have the same numer of elements, number of \n",
    "    layers - 1.\n",
    "    \"\"\"\n",
    "    L = len(architecture)\n",
    "    W, b = [], []\n",
    "    # initializare de ponderi\n",
    "    for n_lplus1, nl in zip(architecture[1:], architecture[:-1]):\n",
    "        W.append(np.random.uniform(-np.sqrt(6)/(np.sqrt(nl + n_lplus1)), +np.sqrt(6)/(np.sqrt(nl + n_lplus1)), (n_lplus1, nl)))     # scrieti cod\n",
    "    for n_l in architecture[1:]:\n",
    "        b.append(np.zeros((n_l, 1)))                      # scrieti cod\n",
    "    assert len(W) == len(b) == L-1\n",
    "    for i, w in enumerate(W):\n",
    "        assert w.shape == (architecture[i+1], architecture[i]), f'Shape of W[{i}] should be ({L[i+1], L[i]})'\n",
    "    for i, _b in enumerate(b):\n",
    "        assert _b.shape == (architecture[i+1], 1), f'Shape of b[{i}] should be ({L[i+1]}, 1)'\n",
    "    if init_type == 'glorot_uniform':\n",
    "        for i, w in enumerate(W):\n",
    "            w_shape_sum = np.sum(w.shape)\n",
    "            assert -np.sqrt(6)/np.sqrt(w_shape_sum) <= np.min(w) <= np.sqrt(6)/np.sqrt(w_shape_sum), f\"Values of W[{i}] should be according to Glorot's initialization\"\n",
    "        for i, _b in enumerate(b):\n",
    "            assert 0 == np.min(_b) == np.min(_b) == 0, f\"Values of b[{i}] should be initialized to 0\"\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.584519Z",
     "start_time": "2020-04-15T05:32:38.569559Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))                                 # scrieti cod\n",
    "\n",
    "def derivate_sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the sigmoid activation function\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))                        # scrieti cod\n",
    "\n",
    "def tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the tanh activation function\"\"\"\n",
    "    return np.tanh(z)                                           # scrieti cod\n",
    "    # (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "def derivate_tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the tanh activation function\"\"\"\n",
    "    return 1 - np.square(tanh(z))                               # scrieti cod\n",
    "\n",
    "def ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the rectified linear unit activation function\"\"\"\n",
    "    return np.max(0, z)                                         # scrieti cod\n",
    "\n",
    "def derivative_ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives of the rectified linear unit activation function\"\"\"\n",
    "    return 0 if z < 0 else 1                                    # scrieti cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.596496Z",
     "start_time": "2020-04-15T05:32:38.589506Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z, axis=0):\n",
    "    \"\"\"Applies softmax to a matrix z.\n",
    "    :param z: np.array of shape (m, k)\n",
    "    \"\"\"\n",
    "    # scrieti cod, posibil mai multe linii\n",
    "    max_z = np.max(z, axis=axis, keepdims=True)\n",
    "    exp_z = np.exp(z - max_z)                                                   # calcul de exponentiala; folositi trucul dat in curs, utilizand max_z\n",
    "    sum_exp_z = (np.sum(exp_z, axis = axis))                                    # scrieti cod\n",
    "    result = exp_z / sum_exp_z                                                  # scrieti cod; se face normalizarea valorilor; considerati ultimul asert\n",
    "    assert np.allclose(np.sum(result, axis=axis), 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.609453Z",
     "start_time": "2020-04-15T05:32:38.599481Z"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "W, b = create_weights(architecture=architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:54:14.739424Z",
     "start_time": "2020-04-15T15:54:14.320545Z"
    }
   },
   "outputs": [],
   "source": [
    "def can_multiply(a:np.array, b:np.array) -> bool:\n",
    "    return a.ndim == b.ndim == 2 and a.shape[1] == b.shape[0]\n",
    "\n",
    "def can_multiply_hadamard(a:np.array, b:np.array) -> bool:\n",
    "    return a.shape == b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.636381Z",
     "start_time": "2020-04-15T05:32:38.624413Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(X:np.array, W:List[np.array], b:List[np.array], f:List[Callable]) -> np.array:\n",
    "    \"\"\"Computes the output produced by the MLP for the given input X\n",
    "    :param X: np.array of shape (n, p). Each column of X is a datum from a set.\n",
    "    :param W: a list of weight matrices\n",
    "    :param b: a list of bias columns\n",
    "    :param f: a list of activation functions\n",
    "    :return: a matrix of output values produced by MLP, of shape: number of \n",
    "    predicted outputs (e.g. classes), number of input vectors p\n",
    "    \"\"\"\n",
    "    assert len(W) == len(b) == len(f)\n",
    "    p = X.shape[1]\n",
    "    a = X\n",
    "    a_list = []\n",
    "    z_list = []\n",
    "    for i, (_w, _b, _f) in enumerate(zip(W, b, f)):\n",
    "        # variabila i poate fi folosita pentru debug\n",
    "        assert can_multiply(_w, a)\n",
    "        z = np.dot(_w, a) + _b                                 # scrieti cod\n",
    "        z_list.append(z)\n",
    "        assert z.shape == (_w.shape[0], p)\n",
    "        a = _f(z)                                       # scrieti cod\n",
    "        a_list.append(a)\n",
    "        assert a.shape == z.shape\n",
    "    assert a.shape == (W[-1].shape[0], p)\n",
    "    return a, z_list, a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.852801Z",
     "start_time": "2020-04-15T05:32:38.639373Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10, 60000) \n\n(10, 60000)\n"
    }
   ],
   "source": [
    "# f[0] = functia de activare pe primul strat ascuns; \n",
    "# f[1] = functia de activare pe al doilea strat ascuns etc.\n",
    "f = [sigmoid, softmax]\n",
    "f_prim = [derivate_sigmoid, softmax]\n",
    "\n",
    "y_hat, z_list, a_list = model(X_train, W, b, f)\n",
    "\n",
    "print(z_list[1].shape, \"\\n\")\n",
    "print(a_list[1].shape)\n",
    "\n",
    "assert y_hat.shape == (m, p)\n",
    "assert np.allclose(y_hat.sum(axis=0), np.ones(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:44.535803Z",
     "start_time": "2020-04-15T05:32:44.527825Z"
    }
   },
   "outputs": [],
   "source": [
    "def J(X, y, W, b, f, num_classes=10, _lambda=0.01):\n",
    "    \"\"\"Computes the error function for MLP\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k)\n",
    "    :param W: list pf MLPs weights\n",
    "    :param b: list pf MLPs biases\n",
    "    :return: loss values, composed of cross entropy + penalty term\n",
    "    \"\"\"\n",
    "    p = X.shape[1]\n",
    "    EPS = 1e-5\n",
    "    # computes a one hot encoding for the given classes:\n",
    "    # if y[i]=c, 0 <= c <= 9 (here), then column i in one_hot_encoding is filled\n",
    "    # in with 0, excepting line c where one finds value 1\n",
    "    one_hot_encoding = np.zeros((num_classes, p), dtype=int)\n",
    "    rows = np.arange(y.shape[1])\n",
    "    one_hot_encoding[y[0, rows], rows] = 1                              # scrieti cod\n",
    "    assert np.all(one_hot_encoding.sum(axis=0) == 1)\n",
    "    predicted, _, _ = model(X, W, b, f)\n",
    "    predicted = np.clip(predicted, EPS, 1-EPS)\n",
    "    loss1 = -1 * np.sum(np.sum(one_hot_encoding * np.log(predicted)))    # scrieti cod\n",
    "    loss2 = (_lambda / 2) * np.sum(np.sum(np.square(W[1:])))\n",
    "    return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.074986Z",
     "start_time": "2020-04-02T05:08:15.069005Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(X:np.array, y:np.array, W: List[np.array], b: List[np.array], f:List[Callable]) -> float:\n",
    "    \"\"\"Computes the accuracy on a given input dataset X, with ground truth y\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k); each value is the index of a class\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activation functions. the last one must be softmax\n",
    "    :return: ratio between correctly classified vectors and total number of cases\n",
    "    \"\"\"\n",
    "    y_hat, _, _ = model(X, W, b, f)                                           # scrieti cod\n",
    "    y_predicted = np.argmax(y_hat, axis=0).reshape(y.shape[1], 1)       # scrieti cod\n",
    "    return (y_predicted == y).sum() / X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(X:np.array, y:np.array, W:List[np.array], b:List[np.array], f:List[Callable], num_class:int):\n",
    "    delta_W = []\n",
    "    delta_b = []\n",
    "    for n_lplus1, nl in zip(architecture[1:], architecture[:-1]):\n",
    "        delta_W.append(np.zeros((n_lplus1, nl), dtype=float))\n",
    "    for n_l in architecture[1:]:\n",
    "        delta_b.append(np.zeros((n_l, 1), dtype=float))\n",
    "    l = len(W)\n",
    "    p = X.shape[1]\n",
    "    j = np.arange(p)\n",
    "    one_hot_encoding = np.zeros((num_class, p))\n",
    "    one_hot_encoding[y[0,j].astype(int), j] = 1\n",
    "    for i in range(p):\n",
    "        y_hat, z_list, a_list = model(X[:,i].reshape((-1,1)), W, b, f)\n",
    "        signals = []\n",
    "        signals.insert(0, y_hat - one_hot_encoding[:,i].reshape((-1,1)))\n",
    "        for j in range(l-2, -1, -1):\n",
    "            signals.insert(0, np.dot(W[j+1].transpose(), signals[0]) * f[j](z_list[j]))\n",
    "        print('signals[0].shape', signals[0].shape)\n",
    "        print('signals[1].shape', signals[1].shape)\n",
    "        J_W = []\n",
    "        J_b = []\n",
    "        print('a_list[0].shape', a_list[0].shape)\n",
    "        print('a_list[1].shape', a_list[1].shape)\n",
    "        for j in range(l):\n",
    "            J_W.append(np.outer(signals[j], np.transpose(a_list[j-1])))\n",
    "            J_b.append(signals[j])\n",
    "        print('J_W[0].shape', J_W[0].shape)\n",
    "        print('J_W[1].shape', J_W[1].shape)\n",
    "        print('delta_W[0].shape', delta_W[0].shape)\n",
    "        print('delta_W[1].shape', delta_W[1].shape)\n",
    "        for j in range(l):\n",
    "            delta_W[j] += J_W[j]\n",
    "            delta_b[j] += J_b[j]\n",
    "    return delta_W, delta_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.098922Z",
     "start_time": "2020-04-02T05:08:15.078976Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train: np.array, y_train: np.array, X_test: np.array, y_test: np.array, num_classes, W: List[np.array], b:List[np.array], f:List[Callable], _lambda: float, alpha: float, max_delta_error:float=1e-4) -> Tuple[List[np.array], List[np.array], List[float], List[float], List[float]]:\n",
    "    \"\"\"Runs the training on the training dataset (X, y). Stops when  \n",
    "    difference between  two succesive error values is lower than :param max_delta_error:\n",
    "    :param X_train: np.array of shape (n, k), with training cases. Each column is a training case\n",
    "    :param y_train: np.array of shape (1, k), containing labels (0=class 0, ...)\n",
    "    :param X_test: np.array of shape (n, l), with test cases. Each column is a test vector\n",
    "    :param y_test: np.array of shape (1, l), containing labels (0=class 0, ...)\n",
    "    :param num_classes: number of classes\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activations functions; the last one must be softmax\n",
    "    :param _lambda: coefficient >= for the L2 penalty term\n",
    "    :param alpha: > 0, learning rate\n",
    "    :max_delta_error: >0, a threshold for max absolute difference of succesive loss values\n",
    "    :return: a tuple consisting of: list of weight matrices, list of biases, list of errors computed at each epoch on training set, 2 lists of accuracies on training and on test set at each epoch\n",
    "    \"\"\"\n",
    "    errors = [J(X_train, y_train, W, b, f, num_classes, _lambda)]\n",
    "    acc_train = [accuracy(X_train, y_train, W, b, f)]\n",
    "    acc_test = [accuracy(X_test, y_test, W, b, f)]\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        epoch += 1\n",
    "        print(epoch)\n",
    "        # actualizare ponderi si biases W, b pentru fiecare pereche de date din setul de instruire *_test\n",
    "        new_W, new_b = delta(X_train, y_train, W, b, f_prim, num_classes)\n",
    "\n",
    "        W -= alpha * (1/X_train.shape[1] * new_W + _lambda * W)\n",
    "        b -= alpha * 1/X_train.shape[1] * new_b\n",
    "\n",
    "        # predicted = model(X_train, W, b, f)\n",
    "        # derivative2 = (1.0/X_train.shape[1]) * (predicted - y_train)\n",
    "        # print(derivative2.T.shape)\n",
    "        # print(predicted.shape)\n",
    "        # new_theta2 = predicted.T.dot(derivative2) + (_lambda / X_train.shape[1]) * W[0]\n",
    "        # new_bias2 = np.sum(derivative2, axis = 0, keepdims = True)\n",
    "    \n",
    "        # derivative1 = derivative2.dot(W[1]) * derivate_sigmoid(predicted[0])\n",
    "        # new_theta1 = derivative1.T.dot(X_train) + (_lambda / X_train.shape[1]) * W[0]\n",
    "        # new_bias1 = np.sum(derivative1, axis = 0, keepdims = True)\n",
    "\n",
    "        # W[0] -= alpha * new_theta1\n",
    "        # b[0] -= alpha * new_bias1\n",
    "\n",
    "        # W[1] -= alpha * new_theta2\n",
    "        # b[1] -= alpha * new_bias2\n",
    "\n",
    "        error = J(X_train, y_train, W, b, f, num_classes, _lambda) # scrieti cod\n",
    "        errors.append(error)\n",
    "        train_acc = accuracy(X_train, y_train, W, b, f) # scrieti cod\n",
    "        acc_train.append(train_acc)\n",
    "        test_acc = accuracy(X_test, y_test, W, b, f) # scrieti cod\n",
    "        acc_test.append(test_acc)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, error: {error}, train accuracy: {train_acc}, test accuracy: {test_acc}')\n",
    "        if np.abs(errors[-1] - errors[-2]) < max_delta_error:\n",
    "            acc_test.append(test_acc)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, error: {error}, train accuracy: {train_acc}, test accuracy: {test_acc}')\n",
    "        print(np.abs(errors[-1] - errors[-2]))\n",
    "        if np.abs(errors[-1] - errors[-2]) < max_delta_error:\n",
    "            break\n",
    "        # plot de valore de eroare pe train si pe test\n",
    "    return W, b, errors, acc_train, acc_test     # scrieti cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:44:41.944041Z",
     "start_time": "2020-04-02T05:52:03.345797Z"
    },
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\nsignals[0].shape (100, 1)\nsignals[1].shape (10, 1)\na_list[0].shape (100, 1)\na_list[1].shape (10, 1)\nJ_W[0].shape (100, 10)\nJ_W[1].shape (10, 100)\ndelta_W[0].shape (100, 784)\ndelta_W[1].shape (10, 100)\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,784) (100,10) (100,784) ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-0e596d4796c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# scrieti cod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-282-977f4f935910>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, X_test, y_test, num_classes, W, b, f, _lambda, alpha, max_delta_error)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# actualizare ponderi si biases W, b pentru fiecare pereche de date din setul de instruire *_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mnew_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_prim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnew_W\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-281-a3b472ced92f>\u001b[0m in \u001b[0;36mdelta\u001b[0;34m(X, y, W, b, f, num_class)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delta_W[1].shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mdelta_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mJ_W\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mdelta_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mJ_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,784) (100,10) (100,784) "
     ]
    }
   ],
   "source": [
    "W, b = create_weights(architecture)\n",
    "\n",
    "W, b, errors, acc_train, acc_test = train(X_train, y_train, X_test, y_test, 10, W, b, f, 0.01, 0.5)   # scrieti cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals[0].shape (100, 1)\n",
    "signals[1].shape (10, 1)\n",
    "a_list[0].shape (100, 1)\n",
    "a_list[1].shape (10, 1)\n",
    "J_W[0].shape (100, 10)\n",
    "J_W[1].shape (10, 100)\n",
    "delta_W[0].shape (100, 784)\n",
    "delta_W[1].shape (10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:03:19.902932Z",
     "start_time": "2020-04-02T14:03:19.673520Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'errors' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-d94ed53ed7ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss on train DS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'errors' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(errors, label='Loss on train DS')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:08:45.594232Z",
     "start_time": "2020-04-02T14:08:45.419907Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'acc_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-d6a806440963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# acc_train, acc_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Acc train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Acc test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_train' is not defined"
     ]
    }
   ],
   "source": [
    "# acc_train, acc_test\n",
    "plt.plot(acc_train, label='Acc train')\n",
    "plt.plot(acc_test, label='Acc test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:12:22.914348Z",
     "start_time": "2020-04-02T05:12:22.885426Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy on test set: 1050.9165\n"
    }
   ],
   "source": [
    "print(f'Accuracy on test set: {accuracy(X_test, y_test, W, b, f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ia': conda)",
   "language": "python",
   "name": "python37664bitiaconda90a31a080f914cbaa28bfd972b8621f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}