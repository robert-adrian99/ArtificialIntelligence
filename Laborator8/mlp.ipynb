{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.688762Z",
     "start_time": "2020-04-15T05:32:33.683775Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.703722Z",
     "start_time": "2020-04-15T05:32:33.694747Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_file(path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the data from the file stored at :param path: and returns the \n",
    "    input values and the class labels.\n",
    "    :param path: path of a CVS file with data\n",
    "    :return: a tuple containing the input matrix of shape (n, p) and a line \n",
    "    vector with the m class labels in {0, ..., 9}\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, header = None)                   # citire date din fisierul dat de path\n",
    "    X = df.values[:, :-1].transpose()                       # scrieti cod\n",
    "    y = df.values[:, -1].reshape(-1,1).transpose()          # scrieti cod\n",
    "    assert X.ndim ==  2, 'Matrix required for input values'\n",
    "    assert y.ndim == 2, 'Column matrix required for labels'\n",
    "    assert y.shape == (1, X.shape[1]), 'Same number of lines is required'\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.710703Z",
     "start_time": "2020-04-15T05:32:33.706715Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train = './data/mnist_train.csv'\n",
    "path_test = './data/mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.182596Z",
     "start_time": "2020-04-15T05:32:33.713696Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_file(path_train)\n",
    "assert X_train.shape == (784, 60000)\n",
    "assert y_train.shape == (1, 60000)\n",
    "\n",
    "X_test, y_test = load_file(path_test)\n",
    "assert X_test.shape == (784, 10000)\n",
    "assert y_test.shape == (1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.194562Z",
     "start_time": "2020-04-15T05:32:38.184589Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_values(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Scales the values to range [0, 1].\n",
    "    :param X: an (m, n) matrix with values between 0 and 255.\n",
    "    :return: an (m, n) matrix containing values of :param X: scaled in [0, 1]\n",
    "    \"\"\"\n",
    "    result = np.divide(X, np.max(X))                 # scrieti cod\n",
    "    assert 0 <= np.min(result) <= np.max(result) <= 1, 'Scaled values should be in [0, 1]'\n",
    "    assert X.shape == result.shape, 'Scaling preserves shape'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.531663Z",
     "start_time": "2020-04-15T05:32:38.203540Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = scale_values(X_train)\n",
    "assert X_train.shape == (784, 60000)\n",
    "X_test = scale_values(X_test)\n",
    "assert X_test.shape == (784, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:41:07.997557Z",
     "start_time": "2019-11-24T15:41:07.991110Z"
    }
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.541636Z",
     "start_time": "2020-04-15T05:32:38.535651Z"
    }
   },
   "outputs": [],
   "source": [
    "m = 10                          # number of classes\n",
    "n, p = X_train.shape\n",
    "architecture = [n, 100, m]      # list: [input_size, hidden1, hidden2, ..., output_size]\n",
    "\n",
    "assert len(architecture) >= 3, 'At least one hidden layer'\n",
    "assert architecture[0] == n\n",
    "assert architecture[-1] == m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponderile sunt initializate conform strategiei lui Xavier Glorot. Pentru o matrice de ponderi $W^{[l]}$ de forma $n_{l} \\times n_{l-1}$, ponderile pot fi initializate cu o distributie uniforma in intervalul \n",
    "$$\n",
    "\\left[-\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}, +\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}\\right]\n",
    "$$\n",
    "\n",
    "Ponderile de bias se obisnuiesc a se initializa cu 0; intializarea aleatoare a ponderilor W este considerata suficienta pentru a obtine spargerea simetriei.\n",
    "\n",
    "Ref: [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.567564Z",
     "start_time": "2020-04-15T05:32:38.545624Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_weights(architecture: List[int], init_type:str='glorot_uniform') -> Tuple[List[np.array], List[np.array]]:\n",
    "    \"\"\"Creates the list of weights and biases for the given architecture.\n",
    "    :param architecture: list of number of nodes in each layer \n",
    "    (including input and ouotput layers)\n",
    "    :param init_type: name of initialization parameter. Defaults to \n",
    "    'glorot_uniform', add other supported initializtion strategies.\n",
    "    :return: a tuple containing: list of weight matrices W, a list of bias \n",
    "    column vectors. The two lists have the same numer of elements, number of \n",
    "    layers - 1.\n",
    "    \"\"\"\n",
    "    L = len(architecture)\n",
    "    W, b = [], []\n",
    "    # initializare de ponderi\n",
    "    for n_lplus1, nl in zip(architecture[1:], architecture[:-1]):\n",
    "        W.append(np.random.uniform(-np.sqrt(6)/(np.sqrt(nl + n_lplus1)), +np.sqrt(6)/(np.sqrt(nl + n_lplus1)), (n_lplus1, nl)))     # scrieti cod\n",
    "    for n_l in architecture[1:]:\n",
    "        b.append(np.zeros((n_l, 1)))                      # scrieti cod\n",
    "    assert len(W) == len(b) == L-1\n",
    "    for i, w in enumerate(W):\n",
    "        assert w.shape == (architecture[i+1], architecture[i]), f'Shape of W[{i}] should be ({L[i+1], L[i]})'\n",
    "    for i, _b in enumerate(b):\n",
    "        assert _b.shape == (architecture[i+1], 1), f'Shape of b[{i}] should be ({L[i+1]}, 1)'\n",
    "    if init_type == 'glorot_uniform':\n",
    "        for i, w in enumerate(W):\n",
    "            w_shape_sum = np.sum(w.shape)\n",
    "            assert -np.sqrt(6)/np.sqrt(w_shape_sum) <= np.min(w) <= np.sqrt(6)/np.sqrt(w_shape_sum), f\"Values of W[{i}] should be according to Glorot's initialization\"\n",
    "        for i, _b in enumerate(b):\n",
    "            assert 0 == np.min(_b) == np.min(_b) == 0, f\"Values of b[{i}] should be initialized to 0\"\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.584519Z",
     "start_time": "2020-04-15T05:32:38.569559Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))                                 # scrieti cod\n",
    "\n",
    "def derivate_sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the sigmoid activation function\"\"\"\n",
    "    return np.exp(z)/ ((np.exp(z) + 1) ** 2) # scrieti cod\n",
    "    # return sigmoid(z) * (1 - sigmoid(z))\n",
    "    # np.sum(np.exp(z) / (1 + np.exp(z)))\n",
    "\n",
    "def tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the tanh activation function\"\"\"\n",
    "    return np.tanh(z)                                           # scrieti cod\n",
    "    # (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "def derivate_tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the tanh activation function\"\"\"\n",
    "    return 1 - np.square(tanh(z))                               # scrieti cod\n",
    "\n",
    "def ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the rectified linear unit activation function\"\"\"\n",
    "    return np.max(0, z)                                         # scrieti cod\n",
    "\n",
    "def derivative_ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives of the rectified linear unit activation function\"\"\"\n",
    "    return 0 if z < 0 else 1                                    # scrieti cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.596496Z",
     "start_time": "2020-04-15T05:32:38.589506Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z, axis=0):\n",
    "    \"\"\"Applies softmax to a matrix z.\n",
    "    :param z: np.array of shape (m, k)\n",
    "    \"\"\"\n",
    "    # scrieti cod, posibil mai multe linii\n",
    "    max_z = np.max(z, axis=axis, keepdims=True)\n",
    "    exp_z = np.exp(z - max_z)                                                  # calcul de exponentiala; folositi trucul dat in curs, utilizand max_z\n",
    "    sum_exp_z = (np.sum(exp_z, axis = axis)).reshape(z.shape[0], 1)            # scrieti cod\n",
    "    result = exp_z / sum_exp_z                                                 # scrieti cod; se face normalizarea valorilor; considerati ultimul asert\n",
    "    assert np.allclose(np.sum(result, axis=axis), 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.609453Z",
     "start_time": "2020-04-15T05:32:38.599481Z"
    }
   },
   "outputs": [],
   "source": [
    "W, b = create_weights(architecture=architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:54:14.739424Z",
     "start_time": "2020-04-15T15:54:14.320545Z"
    }
   },
   "outputs": [],
   "source": [
    "def can_multiply(a:np.array, b:np.array) -> bool:\n",
    "    return a.ndim == b.ndim == 2 and a.shape[1] == b.shape[0]\n",
    "\n",
    "def can_multiply_hadamard(a:np.array, b:np.array) -> bool:\n",
    "    return a.shape == b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.636381Z",
     "start_time": "2020-04-15T05:32:38.624413Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-e25137695e67>, line 16)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-e25137695e67>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    z = # scrieti cod\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def model(X:np.array, W:List[np.array], b:List[np.array], f:List[Callable]) -> np.array:\n",
    "    \"\"\"Computes the output produced by the MLP for the given input X\n",
    "    :param X: np.array of shape (n, p). Each column of X is a datum from a set.\n",
    "    :param W: a list of weight matrices\n",
    "    :param b: a list of bias columns\n",
    "    :param f: a list of activation functions\n",
    "    :return: a matrix of output values produced by MLP, of shape: number of \n",
    "    predicted outputs (e.g. classes), number of input vectors p\n",
    "    \"\"\"\n",
    "    assert len(W) == len(b) == len(f)\n",
    "    p = X.shape[1]\n",
    "    a = X\n",
    "    for i, (_w, _b, _f) in enumerate(zip(W, b, f)):\n",
    "        # variabila i poate fi folosita pentru debug\n",
    "        print(i)\n",
    "        assert can_multiply(_w, a)\n",
    "        z = _w[i - 1] * a[i - 1] + b[i - 1] # scrieti cod\n",
    "        assert z.shape == (_w.shape[0], p)\n",
    "        a =  # scrieti cod\n",
    "        assert a.shape == z.shape\n",
    "    assert a.shape == (W[-1].shape[0], p)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.852801Z",
     "start_time": "2020-04-15T05:32:38.639373Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'softmax' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a58a598ebc0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# f[0] = functia de activare pe primul strat ascuns;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# f[1] = functia de activare pe al doilea strat ascuns etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'softmax' is not defined"
     ]
    }
   ],
   "source": [
    "# f[0] = functia de activare pe primul strat ascuns; \n",
    "# f[1] = functia de activare pe al doilea strat ascuns etc.\n",
    "f = [sigmoid, softmax] \n",
    "y_hat = model(X_train, W, b, f)\n",
    "\n",
    "assert y_hat.shape == (m, p)\n",
    "assert np.allclose(y_hat.sum(axis=0), np.ones(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:44.535803Z",
     "start_time": "2020-04-15T05:32:44.527825Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-3adf761a725a>, line 14)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-3adf761a725a>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    one_hot_encoding = # scrieti cod\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def J(X, y, W, b, f, num_classes=10, _lambda=0.01):\n",
    "    \"\"\"Computes the error function for MLP\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k)\n",
    "    :param W: list pf MLPs weights\n",
    "    :param b: list pf MLPs biases\n",
    "    :return: loss values, composed of cross entropy + penalty term\n",
    "    \"\"\"\n",
    "    p = X.shape[1]\n",
    "    EPS = 1e-5\n",
    "    # computes a one hot encoding for the given classes:\n",
    "    # if y[i]=c, 0 <= c <= 9 (here), then column i in one_hot_encoding is filled\n",
    "    # in with 0, excepting line c where one finds value 1\n",
    "    one_hot_encoding = # scrieti cod\n",
    "    assert np.all(one_hot_encoding.sum(axis=0) == 1)\n",
    "    predicted = model(X, W, b, f)\n",
    "    predicted = np.clip(predicted, EPS, 1-EPS)\n",
    "    loss1 = # scrieti cod \n",
    "    loss2 = # scrieti cod\n",
    "    return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.074986Z",
     "start_time": "2020-04-02T05:08:15.069005Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-d32fcfff5593>, line 12)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-d32fcfff5593>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    return (y_predicted == y).sum() / X.shape[1]\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def accuracy(X:np.array, y:np.array, W: List[np.array], b: List[np.array], f:List[Callable]) -> float:\n",
    "    \"\"\"Computes the accuracy on a given input dataset X, with ground truth y\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k); each value is the index of a class\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activation functions. the last one must be softmax\n",
    "    :return: ratio between correctly classified vectors and total number of cases\n",
    "    \"\"\"\n",
    "    y_hat = model(# scrieti cod)\n",
    "    y_predicted = # scrieti cod\n",
    "    return (y_predicted == y).sum() / X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.098922Z",
     "start_time": "2020-04-02T05:08:15.078976Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-48c87242d189>, line 17)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-48c87242d189>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    errors = [J(X_train, y_train, W, b, f, num_classes, _lambda):]\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train(X_train: np.array, y_train: np.array, X_test: np.array, y_test: np.array, num_classes, W: List[np.array], b:List[np.array], f:List[Callable], _lambda: float, alpha: float, max_delta_error:float=1e-4) -> Tuple[List[np.array], List[np.array], List[float], List[float], List[float]]:\n",
    "    \"\"\"Runs the training on the training dataset (X, y). Stops when  \n",
    "    difference between  two succesive error values is lower than :param max_delta_error:\n",
    "    :param X_train: np.array of shape (n, k), with training cases. Each column is a training case\n",
    "    :param y_train: np.array of shape (1, k), containing labels (0=class 0, ...)\n",
    "    :param X_test: np.array of shape (n, l), with test cases. Each column is a test vector\n",
    "    :param y_test: np.array of shape (1, l), containing labels (0=class 0, ...)\n",
    "    :param num_classes: number of classes\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activations functions; the last one must be softmax\n",
    "    :param _lambda: coefficient >= for the L2 penalty term\n",
    "    :param alpha: > 0, learning rate\n",
    "    :max_delta_error: >0, a threshold for max absolute difference of succesive loss values\n",
    "    :return: a tuple consisting of: list of weight matrices, list of biases, list of errors computed at each epoch on training set, 2 lists of accuracies on training and on test set at each epoch\n",
    "    \"\"\"\n",
    "    errors = [J(X_train, y_train, W, b, f, num_classes, _lambda):]\n",
    "    acc_train = [accuracy(X_train, y_train, W, b, f)]\n",
    "    acc_test = [accuracy(X_test, y_test, W, b, f)]\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        epoch += 1\n",
    "        # actualizare ponderi si biases W, b pentru fiecare pereche de date din setul de instruire *_test\n",
    "        error = # scrieti cod\n",
    "        errors.append(error)\n",
    "        train_acc = # scrieti cod\n",
    "        acc_train.append(train_acc)\n",
    "        test_acc = # scrieti cod\n",
    "        acc_test.append(test_acc)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, error: {error}, train accuracy: {train_acc}, test accuracy: {test_acc}')\n",
    "        if np.abs(errors[-1] - errors[-2]) < max_delta_error:\n",
    "            break\n",
    "        # plot de valore de eroare pe train si pe test\n",
    "    return # scrieti cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:44:41.944041Z",
     "start_time": "2020-04-02T05:52:03.345797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-18-6638c208dfd1>, line 3)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-6638c208dfd1>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    W, b, errors, acc_train, acc_test = train(# scrieti cod)\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "W, b = create_weights(architecture)\n",
    "\n",
    "W, b, errors, acc_train, acc_test = train(# scrieti cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:03:19.902932Z",
     "start_time": "2020-04-02T14:03:19.673520Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'errors' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d94ed53ed7ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss on train DS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'errors' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(errors, label='Loss on train DS')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:08:45.594232Z",
     "start_time": "2020-04-02T14:08:45.419907Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'acc_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d6a806440963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# acc_train, acc_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Acc train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Acc test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_train' is not defined"
     ]
    }
   ],
   "source": [
    "# acc_train, acc_test\n",
    "plt.plot(acc_train, label='Acc train')\n",
    "plt.plot(acc_test, label='Acc test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:12:22.914348Z",
     "start_time": "2020-04-02T05:12:22.885426Z"
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2ffd0be0abad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy on test set: {accuracy(X_test, y_test, theta)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on test set: {accuracy(X_test, y_test, theta)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ia': conda)",
   "language": "python",
   "name": "python37664bitiaconda90a31a080f914cbaa28bfd972b8621f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}